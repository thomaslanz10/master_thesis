{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wrf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from netCDF4 import Dataset\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.axisartist as AA\n",
    "from mpl_toolkits.axes_grid1 import host_subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part = 'retrospective_part'\n",
    "\n",
    "if data_part == 'retrospective_part':\n",
    "    wrf_data = '/mnt/climstor/wrfout2/WRF4.0_test51/'\n",    
    "    titan_data = '/scratch3/tim/wrf_4.0.1/P3/tracks/tracks_20180531.csv.gz'\n",
    "else:\n",
    "    wrf_data = '/mnt/climstor/wrfout3/WRF4.0_SCC1_51_1/'\n",
    "    titan_data = '/scratch3/tim/wrf_4.0/P3_CC/tracks/tracks_20180531.csv.gz'\n",
    "\n",
    "# Create a list of all WRF file directories\n",
    "wrflist = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(wrf_data):\n",
    "    wrflist += [ os.path.join(dirpath, file) for file in filenames \n",
    "               if file.startswith('wrfout_d02_2018-05') ]\n",
    "\n",    
    "# Preprocessing of TITAN data\n",    
    "df = pd.read_csv(titan_data, sep=',', header=41)\n",
    "\n",
    "# Selcting storms lasting longer than 10 min (=600s)\n",
    "df_duration_600 = df[df['stormDuration'] > 600]\n",
    "\n",
    "# Reset index\n",
    "df_duration_600 = df_duration_600.reset_index()\n",
    "\n",
    "# Selcting storms initiated over Switzerland (5.5, 11, 45.5, 48)\n",
    "df_ch_min = df_duration_600[(df_duration_600['xCoord'] > 5.9) & (df_duration_600['yCoord'] > 45.75)]\n",
    "df_ch_max = df_ch_min[(df_ch_min['xCoord'] < 10.5) & (df_ch_min['yCoord'] < 47.85)]\n",
    "\n",
    "df_initiations = df_ch_max[df_ch_max['originTime'] == df_ch_max['timestamp'] ]\n",
    "\n",
    "# Reset index\n",
    "df_initiations = df_initiations.reset_index()\n",
    "\n",
    "# Create file with initiation information\n",
    "initiations = df_initiations.filter(['stormID', 'stormDuration', 'xCoord', 'yCoord', 'originTime', \n",
    "                                     'timestamp',], axis='columns')"
    "\n",
    "periods = 4\n",
    "frequency = '30min'\n",
    "\n",
    "initiationTimes = initiations.originTime\n",
    "\n",
    "# Make empty lists\n",
    "t0, t1, t2, t3, t4 = ([] for i in range(5))\n",
    "\n",
    "# Add time steps\n",
    "i=0\n",
    "for i in initiationTimes:     \n",
    "    initiationTime = pd.to_datetime(i)\n",
    "    \n",
    "    date_range = pd.date_range(end=initiationTime, periods=periods+1, \n",
    "                               freq=frequency)\n",
    "    date_range_str = date_range.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    t0.append(date_range_str[-1])\n",
    "    t1.append(date_range_str[-2])\n",
    "    t2.append(date_range_str[-3])\n",
    "    t3.append(date_range_str[-4])\n",
    "    t4.append(date_range_str[-5])\n",
    "\n",
    "initiations['t0'] = t0\n",
    "initiations['t1'] = t1\n",
    "initiations['t2'] = t2\n",
    "initiations['t3'] = t3\n",
    "initiations['t4'] = t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a function that deals with points which have longitudes > STAND_LON\n",
    "def rotated_ll_to_xy(wrfFile, latitude, longitude):\n",
    "    res = wrf.ll_to_xy(wrfFile, latitude=latitude, longitude=longitude)\n",
    "    diffPix = np.round((2*wrf.Constants.WRF_EARTH_RADIUS*wrf.Constants.PI)/wrfFile.DX,0)\n",
    "    xs = np.where(np.ravel(longitude) >= wrfFile.STAND_LON*-1, res[0]+diffPix, res[0])\n",
    "    res[0] = xs[0]\n",
    "    return(res)\n",
    "\n",
    "# Make empty lists\n",
    "cape_t0, cin_t0, wv_850_t0, theta_e_850_t0, \\\n",
    "div_t0, shear_z_t0, shear_m_t0, bulk_shear_t0, updraft_t0 = ([] for i in range(9))\n",
    "cape_t1, cin_t1, wv_850_t1, theta_e_850_t1, \\\n",
    "div_t1, shear_z_t1, shear_m_t1, bulk_shear_t1, updraft_t1 = ([] for i in range(9))\n",
    "cape_t2, cin_t2, wv_850_t2, theta_e_850_t2, \\\n",
    "div_t2, shear_z_t2, shear_m_t2, bulk_shear_t2, updraft_t2 = ([] for i in range(9))\n",
    "cape_t3, cin_t3, wv_850_t3, theta_e_850_t3, \\\n",
    "div_t3, shear_z_t3, shear_m_t3, bulk_shear_t3, updraft_t3 = ([] for i in range(9))\n",
    "cape_t4, cin_t4, wv_850_t4, theta_e_850_t4, \\\n",
    "div_t4, shear_z_t4, shear_m_t4, bulk_shear_t4, updraft_t4 = ([] for i in range(9))\n",
    "        \n",
    "        \n",
    "def any_function(id):\n",
    "    wrfTime = wrflist[id][-19:-9] +'T'+ wrflist[id][-8:]\n",
    "    \n",
    "    # Gather for wrf file initiations for time steps\n",
    "    initiations_t0 = initiations[initiations['t0'] == wrfTime]   \n",
    "    initiations_t1 = initiations[initiations['t1'] == wrfTime]   \n",
    "    initiations_t2 = initiations[initiations['t2'] == wrfTime]\n",
    "    initiations_t3 = initiations[initiations['t3'] == wrfTime]\n",
    "    initiations_t4 = initiations[initiations['t4'] == wrfTime]\n",
    "\n",
    "    if len(initiations_t0)==0 and len(initiations_t1)==0 and len(initiations_t2)==0 \\\n",
    "    and len(initiations_t3)==0 and len(initiations_t4)==0:\n",
    "        pass\n",
    "    else:\n",
    "        # Get variables from wrf file \n",
    "        wrfFile = Dataset(wrflist[id])\n",
    "\n",
    "        cape = wrf.getvar(wrfFile, 'cape_2d')[0,:]\n",
    "        cin = wrf.getvar(wrfFile, 'cape_2d')[1,:]\n",
    "        wv = wrf.getvar(wrfFile, 'QVAPOR')*1000 # convert to g/kg\n",
    "        theta_e = wrf.getvar(wrfFile, 'theta_e')\n",
    "        updraft = wrf.getvar(wrfFile, 'W_UP_MAX')\n",
    "        ua = wrf.getvar(wrfFile, 'ua')\n",
    "        va = wrf.getvar(wrfFile, 'va') \n",
    "        \n",
    "        # Interpolating 3d variables to horizontal pressure level @ 850 hPa\n",
    "        p = wrf.getvar(wrfFile, 'pressure')\n",
    "\n",
    "        wv_850 = wrf.interplevel(wv, p, 850)\n",
    "        wv_850 = wv_850.squeeze()\n",
    "\n",
    "        theta_e_850 = wrf.interplevel(theta_e, p, 850)\n",
    "        theta_e_850 = theta_e_850.squeeze()\n",
    "\n",
    "        u_wind_850 = wrf.interplevel(ua, p, 850)\n",
    "        u_wind_850 = u_wind_850.squeeze() * units.meter / units.second \n",
    "\n",
    "        v_wind_850 = wrf.interplevel(va, p, 850)\n",
    "        v_wind_850 = v_wind_850.squeeze() * units.meter / units.second \n",
    "\n",
    "        u_wind_500 = wrf.interplevel(ua, p, 500)\n",
    "        u_wind_500 = u_wind_500.squeeze() * units.meter / units.second \n",
    "\n",
    "        v_wind_500 = wrf.interplevel(va, p, 500)\n",
    "        v_wind_500 = v_wind_500.squeeze() * units.meter / units.second \n",
    "\n",
    "        dx = 1528.68994140625 * units.meter\n",
    "        dy = 1528.68994140625 * units.meter\n",
    "        div = mpcalc.divergence(u_wind_850, v_wind_850, dx, dy, dim_order='yx')\n",
    "        div = div*1e3\n",
    "        div = xr.DataArray(div)\n",
    "        \n",
    "        wind_shear_zonal = u_wind_500 - u_wind_850\n",
    "        wind_shear_merid = v_wind_500 - v_wind_850\n",
    "        bulk_shear = np.sqrt(wind_shear_zonal**2 + wind_shear_merid**2)\n",
    "            \n",
    "        if len(initiations_t0) != 0:\n",
    "            print('--- intitiations @ t0 ---')\n",
    "            initiations_xy_t0 = rotated_ll_to_xy(wrfFile, initiations_t0.yCoord, \n",
    "                                           initiations_t0.xCoord)\n",
    "\n",
    "            cape_initiations_t0 = cape.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            cape_t0.append(cape_initiations_t0)\n",
    "\n",
    "            cin_initiations_t0 = cin.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            cin_t0.append(cin_initiations_t0)\n",
    "\n",
    "            wv_850_initiations_t0 = wv_850.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            wv_850_t0.append(wv_850_initiations_t0)\n",
    "\n",
    "            theta_e_850_initiations_t0 = theta_e_850.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            theta_e_850_t0.append(theta_e_850_initiations_t0)\n",
    "\n",
    "            div_initiations_t0 = div.sel(dim_1=initiations_xy_t0[0], \n",
    "                                   dim_0=initiations_xy_t0[1])\n",
    "            div_t0.append(div_initiations_t0)\n",
    "\n",
    "            updraft_initiations_t0 = updraft.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            updraft_t0.append(updraft_initiations_t0)\n",
    "\n",
    "            shear_z_initiations_t0 = wind_shear_zonal.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            shear_z_t0.append(shear_z_initiations_t0)\n",
    "\n",
    "            shear_m_initiations_t0 = wind_shear_merid.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            shear_m_t0.append(shear_m_initiations_t0)\n",
    "\n",
    "            bulk_shear_initiations_t0 = bulk_shear.sel(west_east=initiations_xy_t0[0], \n",
    "                                   south_north=initiations_xy_t0[1])\n",
    "            bulk_shear_t0.append(bulk_shear_initiations_t0)\n",
    "\n",
    "        if len(initiations_t1) != 0:\n",
    "            print('--- intitiations @ t1 ---')\n",
    "            initiations_xy_t1 = rotated_ll_to_xy(wrfFile, initiations_t1.yCoord, \n",
    "                                           initiations_t1.xCoord)\n",
    "\n",
    "            cape_initiations_t1 = cape.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            cape_t1.append(cape_initiations_t1)\n",
    "\n",
    "            cin_initiations_t1 = cin.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            cin_t1.append(cin_initiations_t1)\n",
    "\n",
    "            wv_850_initiations_t1 = wv_850.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            wv_850_t1.append(wv_850_initiations_t1)\n",
    "\n",
    "            theta_e_850_initiations_t1 = theta_e_850.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            theta_e_850_t1.append(theta_e_850_initiations_t1)\n",
    "\n",
    "            div_initiations_t1 = div.sel(dim_1=initiations_xy_t1[0], \n",
    "                                   dim_0=initiations_xy_t1[1])\n",
    "            div_t1.append(div_initiations_t1)\n",
    "\n",
    "            updraft_initiations_t1 = updraft.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            updraft_t1.append(updraft_initiations_t1)\n",
    "\n",
    "            shear_z_initiations_t1 = wind_shear_zonal.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            shear_z_t1.append(shear_z_initiations_t1)\n",
    "\n",
    "            shear_m_initiations_t1 = wind_shear_merid.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            shear_m_t1.append(shear_m_initiations_t1)\n",
    "\n",
    "            bulk_shear_initiations_t1 = bulk_shear.sel(west_east=initiations_xy_t1[0], \n",
    "                                   south_north=initiations_xy_t1[1])\n",
    "            bulk_shear_t1.append(bulk_shear_initiations_t1)\n",
    "\n",
    "        if len(initiations_t2) != 0:\n",
    "            print('--- intitiations @ t2 ---')\n",
    "            initiations_xy_t2 = rotated_ll_to_xy(wrfFile, initiations_t2.yCoord, \n",
    "                                           initiations_t2.xCoord)\n",
    "\n",
    "            cape_initiations_t2 = cape.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            cape_t2.append(cape_initiations_t2)\n",
    "\n",
    "            cin_initiations_t2 = cin.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            cin_t2.append(cin_initiations_t2)\n",
    "\n",
    "            wv_850_initiations_t2 = wv_850.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            wv_850_t2.append(wv_850_initiations_t2)\n",
    "\n",
    "            theta_e_850_initiations_t2 = theta_e_850.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            theta_e_850_t2.append(theta_e_850_initiations_t2)\n",
    "\n",
    "            div_initiations_t2 = div.sel(dim_1=initiations_xy_t2[0], \n",
    "                                   dim_0=initiations_xy_t2[1])\n",
    "            div_t2.append(div_initiations_t2)\n",
    "\n",
    "            updraft_initiations_t2 = updraft.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            updraft_t2.append(updraft_initiations_t2)\n",
    "\n",
    "            shear_z_initiations_t2 = wind_shear_zonal.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            shear_z_t2.append(shear_z_initiations_t2)\n",
    "\n",
    "            shear_m_initiations_t2 = wind_shear_merid.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            shear_m_t2.append(shear_m_initiations_t2)\n",
    "\n",
    "            bulk_shear_initiations_t2 = bulk_shear.sel(west_east=initiations_xy_t2[0], \n",
    "                                   south_north=initiations_xy_t2[1])\n",
    "            bulk_shear_t2.append(bulk_shear_initiations_t2)\n",
    "\n",
    "        if len(initiations_t3) != 0:\n",
    "            print('--- intitiations @ t3 ---')\n",
    "            initiations_xy_t3 = rotated_ll_to_xy(wrfFile, initiations_t3.yCoord, \n",
    "                                           initiations_t3.xCoord)\n",
    "\n",
    "            cape_initiations_t3 = cape.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            cape_t3.append(cape_initiations_t3)\n",
    "\n",
    "            cin_initiations_t3 = cin.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            cin_t3.append(cin_initiations_t3)\n",
    "\n",
    "            wv_850_initiations_t3 = wv_850.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            wv_850_t3.append(wv_850_initiations_t3)\n",
    "\n",
    "            theta_e_850_initiations_t3 = theta_e_850.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            theta_e_850_t3.append(theta_e_850_initiations_t3)\n",
    "\n",
    "            div_initiations_t3 = div.sel(dim_1=initiations_xy_t3[0], \n",
    "                                   dim_0=initiations_xy_t3[1])\n",
    "            div_t3.append(div_initiations_t3)\n",
    "\n",
    "            updraft_initiations_t3 = updraft.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            updraft_t3.append(updraft_initiations_t3)\n",
    "\n",
    "            shear_z_initiations_t3 = wind_shear_zonal.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            shear_z_t3.append(shear_z_initiations_t3)\n",
    "\n",
    "            shear_m_initiations_t3 = wind_shear_merid.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            shear_m_t3.append(shear_m_initiations_t3)\n",
    "\n",
    "            bulk_shear_initiations_t3 = bulk_shear.sel(west_east=initiations_xy_t3[0], \n",
    "                                   south_north=initiations_xy_t3[1])\n",
    "            bulk_shear_t3.append(bulk_shear_initiations_t3)\n",
    "\n",
    "        if len(initiations_t4) != 0:\n",
    "            print('--- intitiations @ t4 ---')\n",
    "            initiations_xy_t4 = rotated_ll_to_xy(wrfFile, initiations_t4.yCoord, \n",
    "                                           initiations_t4.xCoord)\n",
    "\n",
    "            cape_initiations_t4 = cape.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            cape_t4.append(cape_initiations_t4)\n",
    "\n",
    "            cin_initiations_t4 = cin.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            cin_t4.append(cin_initiations_t4)\n",
    "\n",
    "            wv_850_initiations_t4 = wv_850.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            wv_850_t4.append(wv_850_initiations_t4)\n",
    "\n",
    "            theta_e_850_initiations_t4 = theta_e_850.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            theta_e_850_t4.append(theta_e_850_initiations_t4)\n",
    "\n",
    "            updraft_initiations_t4 = updraft.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            updraft_t4.append(updraft_initiations_t4)\n",
    "\n",
    "            div_initiations_t4 = div.sel(dim_1=initiations_xy_t4[0], \n",
    "                                   dim_0=initiations_xy_t4[1])\n",
    "            div_t4.append(div_initiations_t4)\n",
    "\n",
    "            shear_z_initiations_t4 = wind_shear_zonal.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            shear_z_t4.append(shear_z_initiations_t4)\n",
    "\n",
    "            shear_m_initiations_t4 = wind_shear_merid.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            shear_m_t4.append(shear_m_initiations_t4)\n",
    "\n",
    "            bulk_shear_initiations_t4 = bulk_shear.sel(west_east=initiations_xy_t4[0], \n",
    "                                   south_north=initiations_xy_t4[1])\n",
    "            bulk_shear_t4.append(bulk_shear_initiations_t4)\n",
    "     \n",
    "  \n",
    "    return cape_t0, cin_t0, wv_850_t0, theta_e_850_t0, \\\n",
    "        div_t0, shear_z_t0, shear_m_t0, bulk_shear_t0, updraft_t0, \\\n",
    "        cape_t1, cin_t1, wv_850_t1, theta_e_850_t1, \\\n",
    "        div_t1, shear_z_t1, shear_m_t1, bulk_shear_t1, updraft_t1, \\\n",
    "        cape_t2, cin_t2, wv_850_t2, theta_e_850_t2, \\\n",
    "        div_t2, shear_z_t2, shear_m_t2, bulk_shear_t2, updraft_t2, \\\n",
    "        cape_t3, cin_t3, wv_850_t3, theta_e_850_t3, \\\n",
    "        div_t3, shear_z_t3, shear_m_t3, bulk_shear_t3, updraft_t3, \\\n",
    "        cape_t4, cin_t4, wv_850_t4, theta_e_850_t4, \\\n",
    "        div_t4, shear_z_t4, shear_m_t4, bulk_shear_t4, updraft_t4\n",
    "\n",
    "def run(f, myIter):\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(f, myIter), total = len(myIter)))\n",
    "    return results\n",
    "\n",
    "results = run(any_function, range(len(wrflist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cape_results_t0 = []\n",
    "cape_results_t1 = []\n",
    "cape_results_t2 = []\n",
    "cape_results_t3 = []\n",
    "cape_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cape_results_t0.extend(r[0])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cape_results_t1.extend(r[9])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cape_results_t2.extend(r[18])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cape_results_t3.extend(r[27])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cape_results_t4.extend(r[36])    \n",
    "\n",
    "cape_results_t0_con = xr.concat(cape_results_t0, dim='idx')\n",
    "cape_results_t0_con[np.isnan(cape_results_t0_con)] = 0\n",
    "cape_results_t0_mean = np.mean(cape_results_t0_con)\n",
    "cape_output_90_t0 = np.percentile(cape_results_t0_con, 90)\n",
    "cape_output_10_t0 = np.percentile(cape_results_t0_con, 10)\n",
    "\n",
    "cape_results_t1_con = xr.concat(cape_results_t1, dim='idx')\n",
    "cape_results_t1_con[np.isnan(cape_results_t1_con)] = 0\n",
    "cape_results_t1_mean = np.mean(cape_results_t1_con)\n",
    "cape_output_90_t1 = np.percentile(cape_results_t1_con, 90)\n",
    "cape_output_10_t1 = np.percentile(cape_results_t1_con, 10)\n",
    "\n",
    "cape_results_t2_con = xr.concat(cape_results_t2, dim='idx')\n",
    "cape_results_t2_con[np.isnan(cape_results_t2_con)] = 0\n",
    "cape_results_t2_mean = np.mean(cape_results_t2_con)\n",
    "cape_output_90_t2 = np.percentile(cape_results_t2_con, 90)\n",
    "cape_output_10_t2 = np.percentile(cape_results_t2_con, 10)\n",
    "\n",
    "cape_results_t3_con = xr.concat(cape_results_t3, dim='idx')\n",
    "cape_results_t3_con[np.isnan(cape_results_t3_con)] = 0\n",
    "cape_results_t3_mean = np.mean(cape_results_t3_con)\n",
    "cape_output_90_t3 = np.percentile(cape_results_t3_con, 90)\n",
    "cape_output_10_t3 = np.percentile(cape_results_t3_con, 10)\n",
    "\n",
    "cape_results_t4_con = xr.concat(cape_results_t4, dim='idx')\n",
    "cape_results_t4_con[np.isnan(cape_results_t4_con)] = 0\n",
    "cape_results_t4_mean = np.mean(cape_results_t4_con)\n",
    "cape_output_90_t4 = np.percentile(cape_results_t4_con, 90)\n",
    "cape_output_10_t4 = np.percentile(cape_results_t4_con, 10)\n",
    "\n",
    "cape_output_mean = [cape_results_t0_mean, cape_results_t1_mean, cape_results_t2_mean, \n",
    "                    cape_results_t3_mean, cape_results_t4_mean]\n",
    "cape_output_90 = [cape_output_90_t0, cape_output_90_t1, cape_output_90_t2, cape_output_90_t3, \n",
    "                  cape_output_90_t4]\n",
    "cape_output_10 = [cape_output_10_t0, cape_output_10_t1, cape_output_10_t2, cape_output_10_t3, \n",
    "                  cape_output_10_t4]\n",
    "print(cape_output_mean, cape_output_90, cape_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cin_results_t0 = []\n",
    "cin_results_t1 = []\n",
    "cin_results_t2 = []\n",
    "cin_results_t3 = []\n",
    "cin_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cin_results_t0.extend(r[1])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cin_results_t1.extend(r[10])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cin_results_t2.extend(r[19])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cin_results_t3.extend(r[28])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        cin_results_t4.extend(r[37])    \n",
    "\n",
    "cin_results_t0_con = xr.concat(cin_results_t0, dim='idx')\n",
    "cin_results_t0_con[np.isnan(cin_results_t0_con)] = 0\n",
    "cin_results_t0_mean = np.mean(cin_results_t0_con)\n",
    "cin_output_90_t0 = np.percentile(cin_results_t0_con, 90)\n",
    "cin_output_10_t0 = np.percentile(cin_results_t0_con, 10)\n",
    "\n",
    "cin_results_t1_con = xr.concat(cin_results_t1, dim='idx')\n",
    "cin_results_t1_con[np.isnan(cin_results_t1_con)] = 0\n",
    "cin_results_t1_mean = np.mean(cin_results_t1_con)\n",
    "cin_output_90_t1 = np.percentile(cin_results_t1_con, 90)\n",
    "cin_output_10_t1 = np.percentile(cin_results_t1_con, 10)\n",
    "\n",
    "cin_results_t2_con = xr.concat(cin_results_t2, dim='idx')\n",
    "cin_results_t2_con[np.isnan(cin_results_t2_con)] = 0\n",
    "cin_results_t2_mean = np.mean(cin_results_t2_con)\n",
    "cin_output_90_t2 = np.percentile(cin_results_t2_con, 90)\n",
    "cin_output_10_t2 = np.percentile(cin_results_t2_con, 10)\n",
    "\n",
    "cin_results_t3_con = xr.concat(cin_results_t3, dim='idx')\n",
    "cin_results_t3_con[np.isnan(cin_results_t3_con)] = 0\n",
    "cin_results_t3_mean = np.mean(cin_results_t3_con)\n",
    "cin_output_90_t3 = np.percentile(cin_results_t3_con, 90)\n",
    "cin_output_10_t3 = np.percentile(cin_results_t3_con, 10)\n",
    "\n",
    "cin_results_t4_con = xr.concat(cin_results_t4, dim='idx')\n",
    "cin_results_t4_con[np.isnan(cin_results_t4_con)] = 0\n",
    "cin_results_t4_mean = np.mean(cin_results_t4_con)\n",
    "cin_output_90_t4 = np.percentile(cin_results_t4_con, 90)\n",
    "cin_output_10_t4 = np.percentile(cin_results_t4_con, 10)\n",
    "\n",
    "cin_output_mean = [cin_results_t0_mean, cin_results_t1_mean, cin_results_t2_mean, \n",
    "                    cin_results_t3_mean, cin_results_t4_mean]\n",
    "cin_output_90 = [cin_output_90_t0, cin_output_90_t1, cin_output_90_t2, cin_output_90_t3, \n",
    "                  cin_output_90_t4]\n",
    "cin_output_10 = [cin_output_10_t0, cin_output_10_t1, cin_output_10_t2, cin_output_10_t3, \n",
    "                  cin_output_10_t4]\n",
    "print(cin_output_mean, cin_output_90, cin_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_850_results_t0 = []\n",
    "wv_850_results_t1 = []\n",
    "wv_850_results_t2 = []\n",
    "wv_850_results_t3 = []\n",
    "wv_850_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        wv_850_results_t0.extend(r[2])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        wv_850_results_t1.extend(r[11])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        wv_850_results_t2.extend(r[20])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        wv_850_results_t3.extend(r[29])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        wv_850_results_t4.extend(r[38])    \n",
    "\n",
    "wv_850_results_t0_con = xr.concat(wv_850_results_t0, dim='idx')\n",
    "wv_850_results_t0_con[np.isnan(wv_850_results_t0_con)] = 0\n",
    "wv_850_results_t0_mean = np.mean(wv_850_results_t0_con)\n",
    "wv_850_output_90_t0 = np.percentile(wv_850_results_t0_con, 90)\n",
    "wv_850_output_10_t0 = np.percentile(wv_850_results_t0_con, 10)\n",
    "\n",
    "wv_850_results_t1_con = xr.concat(wv_850_results_t1, dim='idx')\n",
    "wv_850_results_t1_con[np.isnan(wv_850_results_t1_con)] = 0\n",
    "wv_850_results_t1_mean = np.mean(wv_850_results_t1_con)\n",
    "wv_850_output_90_t1 = np.percentile(wv_850_results_t1_con, 90)\n",
    "wv_850_output_10_t1 = np.percentile(wv_850_results_t1_con, 10)\n",
    "\n",
    "wv_850_results_t2_con = xr.concat(wv_850_results_t2, dim='idx')\n",
    "wv_850_results_t2_con[np.isnan(wv_850_results_t2_con)] = 0\n",
    "wv_850_results_t2_mean = np.mean(wv_850_results_t2_con)\n",
    "wv_850_output_90_t2 = np.percentile(wv_850_results_t2_con, 90)\n",
    "wv_850_output_10_t2 = np.percentile(wv_850_results_t2_con, 10)\n",
    "\n",
    "wv_850_results_t3_con = xr.concat(wv_850_results_t3, dim='idx')\n",
    "wv_850_results_t3_con[np.isnan(wv_850_results_t3_con)] = 0\n",
    "wv_850_results_t3_mean = np.mean(wv_850_results_t3_con)\n",
    "wv_850_output_90_t3 = np.percentile(wv_850_results_t3_con, 90)\n",
    "wv_850_output_10_t3 = np.percentile(wv_850_results_t3_con, 10)\n",
    "\n",
    "wv_850_results_t4_con = xr.concat(wv_850_results_t4, dim='idx')\n",
    "wv_850_results_t4_con[np.isnan(wv_850_results_t4_con)] = 0\n",
    "wv_850_results_t4_mean = np.mean(wv_850_results_t4_con)\n",
    "wv_850_output_90_t4 = np.percentile(wv_850_results_t4_con, 90)\n",
    "wv_850_output_10_t4 = np.percentile(wv_850_results_t4_con, 10)\n",
    "\n",
    "wv_850_output_mean = [wv_850_results_t0_mean, wv_850_results_t1_mean, wv_850_results_t2_mean, \n",
    "                    wv_850_results_t3_mean, wv_850_results_t4_mean]\n",
    "wv_850_output_90 = [wv_850_output_90_t0, wv_850_output_90_t1, wv_850_output_90_t2, wv_850_output_90_t3, \n",
    "                  wv_850_output_90_t4]\n",
    "wv_850_output_10 = [wv_850_output_10_t0, wv_850_output_10_t1, wv_850_output_10_t2, wv_850_output_10_t3, \n",
    "                  wv_850_output_10_t4]\n",
    "print(wv_850_output_mean, wv_850_output_90, wv_850_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patch_spines_invisible(ax):\n",
    "    ax.set_frame_on(True)\n",
    "    ax.patch.set_visible(False)\n",
    "    for sp in ax.spines.values():\n",
    "        sp.set_visible(False)\n",
    "        \n",
    "deltaTime = 2\n",
    "timeSteps = 4\n",
    "\n",
    "time_range = np.linspace(0, deltaTime, timeSteps+1)\n",
    "time_range = time_range * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part = 'prospective_part'\n",
    "cape_output_mean = cape_output_mean_CC\n",
    "cin_output_mean = cin_output_mean_CC\n",
    "wv_850_output_mean = wv_850_output_mean_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAPE, CIN and Water Vapor plot\n",
    "fig, host = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "fig.subplots_adjust(right=0.75)\n",
    "\n",
    "par1 = host.twinx()\n",
    "par2 = host.twinx()\n",
    "\n",
    "par2.spines[\"right\"].set_position((\"axes\", 1.15))\n",
    "make_patch_spines_invisible(par2)\n",
    "par2.spines[\"right\"].set_visible(True)\n",
    "\n",
    "p1, = host.plot(time_range, cape_output_mean, label='CAPE', color='r', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "p2, = par1.plot(time_range, cin_output_mean, label='CIN', color='b', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "p3, = par2.plot(time_range, wv_850_output_mean, label='Water Vapor', color='dimgray', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "host.set_xlim(0, 120)\n",
    "if data_part == 'retrospective_part':\n",
    "    host.set_ylim(320, 500)\n",
    "    par1.set_ylim(7.5, 10)\n",
    "    par2.set_ylim(6.65, 6.9)\n",
    "else:\n",
    "    host.set_ylim(650, 850)\n",
    "    par1.set_ylim(9.5, 13)\n",
    "    par2.set_ylim(8.5, 8.8)\n",
    "\n",
    "host.set_xlabel('Minutes before Thunderstorm Initiation', fontsize=20)\n",
    "host.set_ylabel('CAPE [$J$ $kg^{-1}$]', fontsize=20)\n",
    "par1.set_ylabel('CIN [$J$ $kg^{-1}$]', fontsize=20)\n",
    "par2.set_ylabel('WVMR [$g$ $kg^{-1}$]', fontsize=20)\n",
    "\n",
    "host.yaxis.label.set_color(p1.get_color())\n",
    "par1.yaxis.label.set_color(p2.get_color())\n",
    "par2.yaxis.label.set_color(p3.get_color())\n",
    "\n",
    "tkw = dict(size=10, width=2)\n",
    "host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n",
    "host.tick_params(axis='x', **tkw)\n",
    "\n",
    "tkw = dict(size=5, width=1)\n",
    "host.tick_params(axis='y', which='minor', colors=p1.get_color(), **tkw)\n",
    "par1.tick_params(axis='y', which='minor', colors=p2.get_color(), **tkw)\n",
    "par2.tick_params(axis='y', which='minor', colors=p3.get_color(), **tkw)\n",
    "host.tick_params(axis='x', which='minor', **tkw)\n",
    "\n",
    "host.minorticks_on()\n",
    "par1.minorticks_on()\n",
    "par2.minorticks_on()\n",
    "\n",
    "lines = [p1, p2, p3]\n",
    "\n",
    "leg = host.legend(lines, [l.get_label() for l in lines], fontsize=17.5, loc='lower left')\n",
    "leg.texts[0].set_color(p1.get_color())\n",
    "leg.texts[1].set_color(p2.get_color())\n",
    "leg.texts[2].set_color(p3.get_color())\n",
    "\n",
    "#host.set_title('Temporal Evolution of CAPE [$J$ $kg^{-1}$], CIN [$J$ $kg^{-1}$] \\n' \\\n",
    "#               'and Water Vapor @ 850 hPa [$g$ $kg^{-1}$] before Thunderstorm Initiation', fontsize=15)\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "host.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "host.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "par1.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "par1.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "par2.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "par2.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "\n",
    "host.text(0.05, 0.95, '(a)', transform=host.transAxes,\n",
    "  fontsize=25, fontweight='bold', va='top', zorder=10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/scratch3/thomasl/work/{}/titan_evo/' \\\n",
    "            'titan_evo_cape_cin_wv.png'.format(data_part), \n",
    "            bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_850_results_t0 = []\n",
    "theta_850_results_t1 = []\n",
    "theta_850_results_t2 = []\n",
    "theta_850_results_t3 = []\n",
    "theta_850_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        theta_850_results_t0.extend(r[3])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        theta_850_results_t1.extend(r[12])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        theta_850_results_t2.extend(r[21])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        theta_850_results_t3.extend(r[30])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        theta_850_results_t4.extend(r[39])    \n",
    "\n",
    "theta_850_results_t0_con = xr.concat(theta_850_results_t0, dim='idx')\n",
    "theta_850_results_t0_con[np.isnan(theta_850_results_t0_con)] = 0\n",
    "theta_850_results_t0_mean = np.mean(theta_850_results_t0_con)\n",
    "theta_850_output_90_t0 = np.percentile(theta_850_results_t0_con, 90)\n",
    "theta_850_output_10_t0 = np.percentile(theta_850_results_t0_con, 10)\n",
    "\n",
    "theta_850_results_t1_con = xr.concat(theta_850_results_t1, dim='idx')\n",
    "theta_850_results_t1_con[np.isnan(theta_850_results_t1_con)] = 0\n",
    "theta_850_results_t1_mean = np.mean(theta_850_results_t1_con)\n",
    "theta_850_output_90_t1 = np.percentile(theta_850_results_t1_con, 90)\n",
    "theta_850_output_10_t1 = np.percentile(theta_850_results_t1_con, 10)\n",
    "\n",
    "theta_850_results_t2_con = xr.concat(theta_850_results_t2, dim='idx')\n",
    "theta_850_results_t2_con[np.isnan(theta_850_results_t2_con)] = 0\n",
    "theta_850_results_t2_mean = np.mean(theta_850_results_t2_con)\n",
    "theta_850_output_90_t2 = np.percentile(theta_850_results_t2_con, 90)\n",
    "theta_850_output_10_t2 = np.percentile(theta_850_results_t2_con, 10)\n",
    "\n",
    "theta_850_results_t3_con = xr.concat(theta_850_results_t3, dim='idx')\n",
    "theta_850_results_t3_con[np.isnan(theta_850_results_t3_con)] = 0\n",
    "theta_850_results_t3_mean = np.mean(theta_850_results_t3_con)\n",
    "theta_850_output_90_t3 = np.percentile(theta_850_results_t3_con, 90)\n",
    "theta_850_output_10_t3 = np.percentile(theta_850_results_t3_con, 10)\n",
    "\n",
    "theta_850_results_t4_con = xr.concat(theta_850_results_t4, dim='idx')\n",
    "theta_850_results_t4_con[np.isnan(theta_850_results_t4_con)] = 0\n",
    "theta_850_results_t4_mean = np.mean(theta_850_results_t4_con)\n",
    "theta_850_output_90_t4 = np.percentile(theta_850_results_t4_con, 90)\n",
    "theta_850_output_10_t4 = np.percentile(theta_850_results_t4_con, 10)\n",
    "\n",
    "theta_850_output_mean = [theta_850_results_t0_mean, theta_850_results_t1_mean, theta_850_results_t2_mean, \n",
    "                    theta_850_results_t3_mean, theta_850_results_t4_mean]\n",
    "theta_850_output_90 = [theta_850_output_90_t0, theta_850_output_90_t1, theta_850_output_90_t2, theta_850_output_90_t3, \n",
    "                  theta_850_output_90_t4]\n",
    "theta_850_output_10 = [theta_850_output_10_t0, theta_850_output_10_t1, theta_850_output_10_t2, theta_850_output_10_t3, \n",
    "                  theta_850_output_10_t4]\n",
    "print(theta_850_output_mean, theta_850_output_90, theta_850_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_850_results_t0 = []\n",
    "div_850_results_t1 = []\n",
    "div_850_results_t2 = []\n",
    "div_850_results_t3 = []\n",
    "div_850_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        div_850_results_t0.extend(r[4])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        div_850_results_t1.extend(r[13])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        div_850_results_t2.extend(r[22])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        div_850_results_t3.extend(r[31])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        div_850_results_t4.extend(r[40])    \n",
    "\n",
    "div_850_results_t0_con = xr.concat(div_850_results_t0, dim='idx')\n",
    "div_850_results_t0_con[np.isnan(div_850_results_t0_con)] = 0\n",
    "div_850_results_t0_mean = np.mean(div_850_results_t0_con)\n",
    "div_850_output_90_t0 = np.percentile(div_850_results_t0_con, 90)\n",
    "div_850_output_10_t0 = np.percentile(div_850_results_t0_con, 10)\n",
    "\n",
    "div_850_results_t1_con = xr.concat(div_850_results_t1, dim='idx')\n",
    "div_850_results_t1_con[np.isnan(div_850_results_t1_con)] = 0\n",
    "div_850_results_t1_mean = np.mean(div_850_results_t1_con)\n",
    "div_850_output_90_t1 = np.percentile(div_850_results_t1_con, 90)\n",
    "div_850_output_10_t1 = np.percentile(div_850_results_t1_con, 10)\n",
    "\n",
    "div_850_results_t2_con = xr.concat(div_850_results_t2, dim='idx')\n",
    "div_850_results_t2_con[np.isnan(div_850_results_t2_con)] = 0\n",
    "div_850_results_t2_mean = np.mean(div_850_results_t2_con)\n",
    "div_850_output_90_t2 = np.percentile(div_850_results_t2_con, 90)\n",
    "div_850_output_10_t2 = np.percentile(div_850_results_t2_con, 10)\n",
    "\n",
    "div_850_results_t3_con = xr.concat(div_850_results_t3, dim='idx')\n",
    "div_850_results_t3_con[np.isnan(div_850_results_t3_con)] = 0\n",
    "div_850_results_t3_mean = np.mean(div_850_results_t3_con)\n",
    "div_850_output_90_t3 = np.percentile(div_850_results_t3_con, 90)\n",
    "div_850_output_10_t3 = np.percentile(div_850_results_t3_con, 10)\n",
    "\n",
    "div_850_results_t4_con = xr.concat(div_850_results_t4, dim='idx')\n",
    "div_850_results_t4_con[np.isnan(div_850_results_t4_con)] = 0\n",
    "div_850_results_t4_mean = np.mean(div_850_results_t4_con)\n",
    "div_850_output_90_t4 = np.percentile(div_850_results_t4_con, 90)\n",
    "div_850_output_10_t4 = np.percentile(div_850_results_t4_con, 10)\n",
    "\n",
    "div_850_output_mean = [div_850_results_t0_mean, div_850_results_t1_mean, div_850_results_t2_mean, \n",
    "                    div_850_results_t3_mean, div_850_results_t4_mean]\n",
    "div_850_output_90 = [div_850_output_90_t0, div_850_output_90_t1, div_850_output_90_t2, div_850_output_90_t3, \n",
    "                  div_850_output_90_t4]\n",
    "div_850_output_10 = [div_850_output_10_t0, div_850_output_10_t1, div_850_output_10_t2, div_850_output_10_t3, \n",
    "                  div_850_output_10_t4]\n",
    "print(div_850_output_mean, div_850_output_90, div_850_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updraft_results_t0 = []\n",
    "updraft_results_t1 = []\n",
    "updraft_results_t2 = []\n",
    "updraft_results_t3 = []\n",
    "updraft_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        updraft_results_t0.extend(r[8])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        updraft_results_t1.extend(r[17])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        updraft_results_t2.extend(r[26])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        updraft_results_t3.extend(r[35])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        updraft_results_t4.extend(r[44])    \n",
    "\n",
    "updraft_results_t0_con = xr.concat(updraft_results_t0, dim='idx')\n",
    "updraft_results_t0_con[np.isnan(updraft_results_t0_con)] = 0\n",
    "updraft_results_t0_mean = np.mean(updraft_results_t0_con)\n",
    "updraft_output_90_t0 = np.percentile(updraft_results_t0_con, 90)\n",
    "updraft_output_10_t0 = np.percentile(updraft_results_t0_con, 10)\n",
    "\n",
    "updraft_results_t1_con = xr.concat(updraft_results_t1, dim='idx')\n",
    "updraft_results_t1_con[np.isnan(updraft_results_t1_con)] = 0\n",
    "updraft_results_t1_mean = np.mean(updraft_results_t1_con)\n",
    "updraft_output_90_t1 = np.percentile(updraft_results_t1_con, 90)\n",
    "updraft_output_10_t1 = np.percentile(updraft_results_t1_con, 10)\n",
    "\n",
    "updraft_results_t2_con = xr.concat(updraft_results_t2, dim='idx')\n",
    "updraft_results_t2_con[np.isnan(updraft_results_t2_con)] = 0\n",
    "updraft_results_t2_mean = np.mean(updraft_results_t2_con)\n",
    "updraft_output_90_t2 = np.percentile(updraft_results_t2_con, 90)\n",
    "updraft_output_10_t2 = np.percentile(updraft_results_t2_con, 10)\n",
    "\n",
    "updraft_results_t3_con = xr.concat(updraft_results_t3, dim='idx')\n",
    "updraft_results_t3_con[np.isnan(updraft_results_t3_con)] = 0\n",
    "updraft_results_t3_mean = np.mean(updraft_results_t3_con)\n",
    "updraft_output_90_t3 = np.percentile(updraft_results_t3_con, 90)\n",
    "updraft_output_10_t3 = np.percentile(updraft_results_t3_con, 10)\n",
    "\n",
    "updraft_results_t4_con = xr.concat(updraft_results_t4, dim='idx')\n",
    "updraft_results_t4_con[np.isnan(updraft_results_t4_con)] = 0\n",
    "updraft_results_t4_mean = np.mean(updraft_results_t4_con)\n",
    "updraft_output_90_t4 = np.percentile(updraft_results_t4_con, 90)\n",
    "updraft_output_10_t4 = np.percentile(updraft_results_t4_con, 10)\n",
    "\n",
    "updraft_output_mean = [updraft_results_t0_mean, updraft_results_t1_mean, updraft_results_t2_mean, \n",
    "                    updraft_results_t3_mean, updraft_results_t4_mean]\n",
    "updraft_output_90 = [updraft_output_90_t0, updraft_output_90_t1, updraft_output_90_t2, updraft_output_90_t3, \n",
    "                  updraft_output_90_t4]\n",
    "updraft_output_10 = [updraft_output_10_t0, updraft_output_10_t1, updraft_output_10_t2, updraft_output_10_t3, \n",
    "                  updraft_output_10_t4]\n",
    "print(updraft_output_mean, updraft_output_90, updraft_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part = 'prospective_part'\n",
    "theta_850_output_mean = theta_850_output_mean_CC\n",
    "div_850_output_mean = div_850_output_mean_CC\n",
    "updraft_output_mean = updraft_output_mean_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta-E, Divergence and Updraft plot\n",
    "fig, host = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "fig.subplots_adjust(right=0.75)\n",
    "\n",
    "par1 = host.twinx()\n",
    "par2 = host.twinx()\n",
    "\n",
    "par2.spines[\"right\"].set_position((\"axes\", 1.15))\n",
    "make_patch_spines_invisible(par2)\n",
    "par2.spines[\"right\"].set_visible(True)\n",
    "\n",
    "p1, = host.plot(time_range, theta_850_output_mean, label='Theta-E', color='darkorange', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "p2, = par1.plot(time_range, div_850_output_mean, label='Divergence', color='purple', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "p3, = par2.plot(time_range, updraft_output_mean, label='Updraft', color='darkgreen', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "host.set_xlim(0, 120)\n",
    "if data_part == 'retrospective_part':\n",
    "    host.set_ylim(267, 270)\n",
    "    par1.set_ylim(-0.25, 0)\n",
    "    par2.set_ylim(0, 7)\n",
    "else:\n",
    "    host.set_ylim(255, 260)\n",
    "    par1.set_ylim(-0.25, 0)\n",
    "    par2.set_ylim(0, 7)\n",
    "\n",
    "host.set_xlabel('Minutes before Thunderstorm Initiation', fontsize=20)\n",
    "host.set_ylabel('Theta-E [$K$]', fontsize=20)\n",
    "par1.set_ylabel('Divergence [$10^{-3}$ $s^{-1}$]', fontsize=20)\n",
    "par2.set_ylabel('Updraft [$m$ $s^-$$^1$]', fontsize=20)\n",
    "\n",
    "host.yaxis.label.set_color(p1.get_color())\n",
    "par1.yaxis.label.set_color(p2.get_color())\n",
    "par2.yaxis.label.set_color(p3.get_color())\n",
    "\n",
    "tkw = dict(size=10, width=2)\n",
    "host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n",
    "host.tick_params(axis='x', **tkw)\n",
    "\n",
    "tkw = dict(size=5, width=1)\n",
    "host.tick_params(axis='y', which='minor', colors=p1.get_color(), **tkw)\n",
    "par1.tick_params(axis='y', which='minor', colors=p2.get_color(), **tkw)\n",
    "par2.tick_params(axis='y', which='minor', colors=p3.get_color(), **tkw)\n",
    "host.tick_params(axis='x', which='minor', **tkw)\n",
    "\n",
    "host.minorticks_on()\n",
    "par1.minorticks_on()\n",
    "par2.minorticks_on()\n",
    "\n",
    "lines = [p1, p2, p3]\n",
    "\n",
    "leg = host.legend(lines, [l.get_label() for l in lines], fontsize=17.5, loc='upper right')\n",
    "leg.texts[0].set_color(p1.get_color())\n",
    "leg.texts[1].set_color(p2.get_color())\n",
    "leg.texts[2].set_color(p3.get_color())\n",
    "\n",
    "#host.set_title('Temporal Evolution of Theta-E @ 850 hPa [$K$], Updraft [$m$ $s^{-1}$] and \\n' \\\n",
    "#               'Divergence @ 850 hPa [$10^{-3}$ $s^{-1}$] before Thunderstorm Initiation', fontsize=15)\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "host.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "host.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "par1.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "par1.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "par2.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "par2.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "\n",
    "host.text(0.05, 0.95, '(b)', transform=host.transAxes, \n",
    "  fontsize=25, fontweight='bold', va='top', zorder=10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/scratch3/thomasl/work/{}/titan_evo/' \\\n",
    "            'titan_evo_theta_e_div_updraft.png'.format(data_part), \n",
    "            bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_z_results_t0 = []\n",
    "shear_z_results_t1 = []\n",
    "shear_z_results_t2 = []\n",
    "shear_z_results_t3 = []\n",
    "shear_z_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_z_results_t0.extend(r[5])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_z_results_t1.extend(r[14])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_z_results_t2.extend(r[23])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_z_results_t3.extend(r[32])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_z_results_t4.extend(r[41])    \n",
    "\n",
    "shear_z_results_t0_con = xr.concat(shear_z_results_t0, dim='idx')\n",
    "shear_z_results_t0_con[np.isnan(shear_z_results_t0_con)] = 0\n",
    "shear_z_results_t0_mean = np.mean(shear_z_results_t0_con)\n",
    "shear_z_output_90_t0 = np.percentile(shear_z_results_t0_con, 90)\n",
    "shear_z_output_10_t0 = np.percentile(shear_z_results_t0_con, 10)\n",
    "\n",
    "shear_z_results_t1_con = xr.concat(shear_z_results_t1, dim='idx')\n",
    "shear_z_results_t1_con[np.isnan(shear_z_results_t1_con)] = 0\n",
    "shear_z_results_t1_mean = np.mean(shear_z_results_t1_con)\n",
    "shear_z_output_90_t1 = np.percentile(shear_z_results_t1_con, 90)\n",
    "shear_z_output_10_t1 = np.percentile(shear_z_results_t1_con, 10)\n",
    "\n",
    "shear_z_results_t2_con = xr.concat(shear_z_results_t2, dim='idx')\n",
    "shear_z_results_t2_con[np.isnan(shear_z_results_t2_con)] = 0\n",
    "shear_z_results_t2_mean = np.mean(shear_z_results_t2_con)\n",
    "shear_z_output_90_t2 = np.percentile(shear_z_results_t2_con, 90)\n",
    "shear_z_output_10_t2 = np.percentile(shear_z_results_t2_con, 10)\n",
    "\n",
    "shear_z_results_t3_con = xr.concat(shear_z_results_t3, dim='idx')\n",
    "shear_z_results_t3_con[np.isnan(shear_z_results_t3_con)] = 0\n",
    "shear_z_results_t3_mean = np.mean(shear_z_results_t3_con)\n",
    "shear_z_output_90_t3 = np.percentile(shear_z_results_t3_con, 90)\n",
    "shear_z_output_10_t3 = np.percentile(shear_z_results_t3_con, 10)\n",
    "\n",
    "shear_z_results_t4_con = xr.concat(shear_z_results_t4, dim='idx')\n",
    "shear_z_results_t4_con[np.isnan(shear_z_results_t4_con)] = 0\n",
    "shear_z_results_t4_mean = np.mean(shear_z_results_t4_con)\n",
    "shear_z_output_90_t4 = np.percentile(shear_z_results_t4_con, 90)\n",
    "shear_z_output_10_t4 = np.percentile(shear_z_results_t4_con, 10)\n",
    "\n",
    "shear_z_output_mean = [shear_z_results_t0_mean, shear_z_results_t1_mean, shear_z_results_t2_mean, \n",
    "                    shear_z_results_t3_mean, shear_z_results_t4_mean]\n",
    "shear_z_output_90 = [shear_z_output_90_t0, shear_z_output_90_t1, shear_z_output_90_t2, shear_z_output_90_t3, \n",
    "                  shear_z_output_90_t4]\n",
    "shear_z_output_10 = [shear_z_output_10_t0, shear_z_output_10_t1, shear_z_output_10_t2, shear_z_output_10_t3, \n",
    "                  shear_z_output_10_t4]\n",
    "print(shear_z_output_mean, shear_z_output_90, shear_z_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shear_m_results_t0 = []\n",
    "shear_m_results_t1 = []\n",
    "shear_m_results_t2 = []\n",
    "shear_m_results_t3 = []\n",
    "shear_m_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_m_results_t0.extend(r[6])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_m_results_t1.extend(r[15])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_m_results_t2.extend(r[24])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_m_results_t3.extend(r[33])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        shear_m_results_t4.extend(r[42])    \n",
    "\n",
    "shear_m_results_t0_con = xr.concat(shear_m_results_t0, dim='idx')\n",
    "shear_m_results_t0_con[np.isnan(shear_m_results_t0_con)] = 0\n",
    "shear_m_results_t0_mean = np.mean(shear_m_results_t0_con)\n",
    "shear_m_output_90_t0 = np.percentile(shear_m_results_t0_con, 90)\n",
    "shear_m_output_10_t0 = np.percentile(shear_m_results_t0_con, 10)\n",
    "\n",
    "shear_m_results_t1_con = xr.concat(shear_m_results_t1, dim='idx')\n",
    "shear_m_results_t1_con[np.isnan(shear_m_results_t1_con)] = 0\n",
    "shear_m_results_t1_mean = np.mean(shear_m_results_t1_con)\n",
    "shear_m_output_90_t1 = np.percentile(shear_m_results_t1_con, 90)\n",
    "shear_m_output_10_t1 = np.percentile(shear_m_results_t1_con, 10)\n",
    "\n",
    "shear_m_results_t2_con = xr.concat(shear_m_results_t2, dim='idx')\n",
    "shear_m_results_t2_con[np.isnan(shear_m_results_t2_con)] = 0\n",
    "shear_m_results_t2_mean = np.mean(shear_m_results_t2_con)\n",
    "shear_m_output_90_t2 = np.percentile(shear_m_results_t2_con, 90)\n",
    "shear_m_output_10_t2 = np.percentile(shear_m_results_t2_con, 10)\n",
    "\n",
    "shear_m_results_t3_con = xr.concat(shear_m_results_t3, dim='idx')\n",
    "shear_m_results_t3_con[np.isnan(shear_m_results_t3_con)] = 0\n",
    "shear_m_results_t3_mean = np.mean(shear_m_results_t3_con)\n",
    "shear_m_output_90_t3 = np.percentile(shear_m_results_t3_con, 90)\n",
    "shear_m_output_10_t3 = np.percentile(shear_m_results_t3_con, 10)\n",
    "\n",
    "shear_m_results_t4_con = xr.concat(shear_m_results_t4, dim='idx')\n",
    "shear_m_results_t4_con[np.isnan(shear_m_results_t4_con)] = 0\n",
    "shear_m_results_t4_mean = np.mean(shear_m_results_t4_con)\n",
    "shear_m_output_90_t4 = np.percentile(shear_m_results_t4_con, 90)\n",
    "shear_m_output_10_t4 = np.percentile(shear_m_results_t4_con, 10)\n",
    "\n",
    "shear_m_output_mean = [shear_m_results_t0_mean, shear_m_results_t1_mean, shear_m_results_t2_mean, \n",
    "                    shear_m_results_t3_mean, shear_m_results_t4_mean]\n",
    "shear_m_output_90 = [shear_m_output_90_t0, shear_m_output_90_t1, shear_m_output_90_t2, shear_m_output_90_t3, \n",
    "                  shear_m_output_90_t4]\n",
    "shear_m_output_10 = [shear_m_output_10_t0, shear_m_output_10_t1, shear_m_output_10_t2, shear_m_output_10_t3, \n",
    "                  shear_m_output_10_t4]\n",
    "print(shear_m_output_mean, shear_m_output_90, shear_m_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_shear_results_t0 = []\n",
    "bulk_shear_results_t1 = []\n",
    "bulk_shear_results_t2 = []\n",
    "bulk_shear_results_t3 = []\n",
    "bulk_shear_results_t4 = []\n",
    "\n",
    "for r in results:\n",
    "    #print(r[0])\n",
    "    if r[0] == []:\n",
    "        continue\n",
    "    else:\n",
    "        bulk_shear_results_t0.extend(r[7])\n",
    "    if r[9] == []:\n",
    "        continue\n",
    "    else:\n",
    "        bulk_shear_results_t1.extend(r[16])\n",
    "    if r[18] == []:\n",
    "        continue\n",
    "    else:\n",
    "        bulk_shear_results_t2.extend(r[25])\n",
    "    if r[27] == []:\n",
    "        continue\n",
    "    else:\n",
    "        bulk_shear_results_t3.extend(r[34])\n",
    "    if r[36] == []:\n",
    "        continue\n",
    "    else:\n",
    "        bulk_shear_results_t4.extend(r[43])    \n",
    "\n",
    "bulk_shear_results_t0_con = xr.concat(bulk_shear_results_t0, dim='idx')\n",
    "bulk_shear_results_t0_con[np.isnan(bulk_shear_results_t0_con)] = 0\n",
    "bulk_shear_results_t0_mean = np.mean(bulk_shear_results_t0_con)\n",
    "bulk_shear_output_90_t0 = np.percentile(bulk_shear_results_t0_con, 90)\n",
    "bulk_shear_output_10_t0 = np.percentile(bulk_shear_results_t0_con, 10)\n",
    "\n",
    "bulk_shear_results_t1_con = xr.concat(bulk_shear_results_t1, dim='idx')\n",
    "bulk_shear_results_t1_con[np.isnan(bulk_shear_results_t1_con)] = 0\n",
    "bulk_shear_results_t1_mean = np.mean(bulk_shear_results_t1_con)\n",
    "bulk_shear_output_90_t1 = np.percentile(bulk_shear_results_t1_con, 90)\n",
    "bulk_shear_output_10_t1 = np.percentile(bulk_shear_results_t1_con, 10)\n",
    "\n",
    "bulk_shear_results_t2_con = xr.concat(bulk_shear_results_t2, dim='idx')\n",
    "bulk_shear_results_t2_con[np.isnan(bulk_shear_results_t2_con)] = 0\n",
    "bulk_shear_results_t2_mean = np.mean(bulk_shear_results_t2_con)\n",
    "bulk_shear_output_90_t2 = np.percentile(bulk_shear_results_t2_con, 90)\n",
    "bulk_shear_output_10_t2 = np.percentile(bulk_shear_results_t2_con, 10)\n",
    "\n",
    "bulk_shear_results_t3_con = xr.concat(bulk_shear_results_t3, dim='idx')\n",
    "bulk_shear_results_t3_con[np.isnan(bulk_shear_results_t3_con)] = 0\n",
    "bulk_shear_results_t3_mean = np.mean(bulk_shear_results_t3_con)\n",
    "bulk_shear_output_90_t3 = np.percentile(bulk_shear_results_t3_con, 90)\n",
    "bulk_shear_output_10_t3 = np.percentile(bulk_shear_results_t3_con, 10)\n",
    "\n",
    "bulk_shear_results_t4_con = xr.concat(bulk_shear_results_t4, dim='idx')\n",
    "bulk_shear_results_t4_con[np.isnan(bulk_shear_results_t4_con)] = 0\n",
    "bulk_shear_results_t4_mean = np.mean(bulk_shear_results_t4_con)\n",
    "bulk_shear_output_90_t4 = np.percentile(bulk_shear_results_t4_con, 90)\n",
    "bulk_shear_output_10_t4 = np.percentile(bulk_shear_results_t4_con, 10)\n",
    "\n",
    "bulk_shear_output_mean = [bulk_shear_results_t0_mean, bulk_shear_results_t1_mean, bulk_shear_results_t2_mean, \n",
    "                    bulk_shear_results_t3_mean, bulk_shear_results_t4_mean]\n",
    "bulk_shear_output_90 = [bulk_shear_output_90_t0, bulk_shear_output_90_t1, bulk_shear_output_90_t2, bulk_shear_output_90_t3, \n",
    "                  bulk_shear_output_90_t4]\n",
    "bulk_shear_output_10 = [bulk_shear_output_10_t0, bulk_shear_output_10_t1, bulk_shear_output_10_t2, bulk_shear_output_10_t3, \n",
    "                  bulk_shear_output_10_t4]\n",
    "print(bulk_shear_output_mean, bulk_shear_output_90, bulk_shear_output_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part = 'retrospective_part'\n",
    "bulk_shear_output_mean = bulk_shear_output_mean_2018\n",
    "shear_z_output_mean = shear_z_output_mean_2018\n",
    "shear_m_output_mean = shear_m_output_mean_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shear plot\n",
    "fig, host = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "fig.subplots_adjust(right=0.75)\n",
    "\n",
    "par1 = host.twinx()\n",
    "par2 = host.twinx()\n",
    "\n",
    "par2.spines[\"right\"].set_position((\"axes\", 1.15))\n",
    "make_patch_spines_invisible(par2)\n",
    "par2.spines[\"right\"].set_visible(True)\n",
    "\n",
    "p1, = host.plot(time_range, bulk_shear_output_mean, label='Bulk Wind Shear', color='brown', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "\n",
    "p2, = par1.plot(time_range, shear_z_output_mean, label='Zonal Wind Shear', color='turquoise', \n",
    "                marker='o', markersize=10, fillstyle='none')\n",
    "\n",
    "p3, = par2.plot(time_range, shear_m_output_mean, label='Meridional Wind Shear', color='hotpink', \n",
    "                marker='o', markersize=10, linestyle='-', fillstyle='none')\n",
    "\n",
    "\n",
    "host.set_xlim(0, 120)\n",
    "if data_part == 'retrospective_part':    \n",
    "    host.set_ylim(6.6, 7.8)\n",
    "    par1.set_ylim(-0.8, -0.3)\n",
    "    par2.set_ylim(2.6, 3.8)\n",
    "else:\n",
    "    host.set_ylim(6.2, 7.2)\n",
    "    par1.set_ylim(-0.8, -0.3)\n",
    "    par2.set_ylim(1.2, 1.5)\n",
    "\n",
    "host.set_xlabel('Minutes before Thunderstorm Initiation', fontsize=20)\n",
    "host.set_ylabel('Bulk Wind Shear [$m$ $s^{-1}$]', fontsize=20)\n",
    "par1.set_ylabel('Zonal Wind Shear [$m$ $s^{-1}$]', fontsize=20)\n",
    "par2.set_ylabel('Meridional Wind Shear [$m$ $s^{-1}$]', fontsize=20)\n",
    "\n",
    "host.yaxis.label.set_color(p1.get_color())\n",
    "par1.yaxis.label.set_color(p2.get_color())\n",
    "par2.yaxis.label.set_color(p3.get_color())\n",
    "\n",
    "tkw = dict(size=10, width=2)\n",
    "host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n",
    "host.tick_params(axis='x', **tkw)\n",
    "\n",
    "tkw = dict(size=5, width=1)\n",
    "host.tick_params(axis='y', which='minor', colors=p1.get_color(), **tkw)\n",
    "par1.tick_params(axis='y', which='minor', colors=p2.get_color(), **tkw)\n",
    "par2.tick_params(axis='y', which='minor', colors=p3.get_color(), **tkw)\n",
    "host.tick_params(axis='x', which='minor', **tkw)\n",
    "\n",
    "host.minorticks_on()\n",
    "par1.minorticks_on()\n",
    "par2.minorticks_on()\n",
    "\n",
    "lines = [p1, p2, p3]\n",
    "\n",
    "leg = host.legend(lines, [l.get_label() for l in lines], fontsize=17.5, loc='lower left')\n",
    "leg.texts[0].set_color(p1.get_color())\n",
    "leg.texts[1].set_color(p2.get_color())\n",
    "leg.texts[2].set_color(p3.get_color())\n",
    "\n",
    "#host.set_title('Temporal Evolution of Bulk Wind Shear, Zonal Wind Shear and \\n' \\\n",
    "#               'Meridional Wind Shear 500-850 hPa [$m$ $s^{-1}$] before Thunderstorm Initiation', fontsize=15)\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "host.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "host.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "par1.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "par1.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "par2.tick_params(axis='both', which='major', labelsize=17.5, length=8, width=1.5)\n",
    "par2.tick_params(axis='both', which='minor', length=4, width=1)\n",
    "\n",
    "host.text(0.05, 0.95, '(c)', transform=host.transAxes, \n",
    "  fontsize=25, fontweight='bold', va='top', zorder=10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/scratch3/thomasl/work/{}/titan_evo/' \\\n",
    "            'titan_evo_shear.png'.format(data_part), \n",
    "            bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda_three-fut_env]",
   "language": "python",
   "name": "conda-env-anaconda_three-fut_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
